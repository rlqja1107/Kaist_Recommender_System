{ 
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.path.abspath(os.path.dirname('__file__'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=torch.tensor([[1,2,3],[2,3,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_path=Path('..')/'ml-1m'/'ratings.dat'\n",
    "rating_data, n_user, n_item=read_rating_data(rating_path)\n",
    "cml=CML(n_user=n_user,n_item=n_item)\n",
    "cml.init_setting(rating_data)\n",
    "cml.data_setting()\n",
    "cml.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import csr_matrix,dok_matrix,lil_matrix\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.path.abspath(os.path.dirname('__file__'))))\n",
    "from pathlib import Path\n",
    "import algo_common_func as ac\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from timeit import default_timer as timer \n",
    "\n",
    "class CML:\n",
    "    def __init__(self,n_user,n_item,n_factor=20,epoch=500,batch_size=500,div_size=0.2,margin=1):\n",
    "        self.n_user=n_user\n",
    "        self.n_item=n_item\n",
    "        self.n_factor=n_factor\n",
    "        self.epoch=epoch\n",
    "        self.margin=margin\n",
    "        self.train_set=None\n",
    "        self.test_set=None\n",
    "        self.div_size=div_size\n",
    "        self.user_id=None\n",
    "        self.item_id=None\n",
    "        self.neg_item_id=None\n",
    "        self.loss=None\n",
    "        self.pred_distance=None\n",
    "        self.pred_distance_neg=None\n",
    "        self.clip_p=None\n",
    "        self.clip_q=None\n",
    "        self.train_data=None\n",
    "        self.teset_data=None\n",
    "        self.batch_size=batch_size\n",
    "        self.csr_train=None\n",
    "        self.csr_test=None\n",
    "        self.test_user=None\n",
    "        self.neg_items=None\n",
    "        self.n_training=0\n",
    "        self.n_batch=0\n",
    "        self.test_dict=None\n",
    "        self.P=None\n",
    "        self.Q=None\n",
    "        self.loss=None\n",
    "        self.relu=None\n",
    "        self.pair_dist=None\n",
    "        \n",
    "        \n",
    "    def init_setting(self,rating_data):\n",
    "        \n",
    "        self.train_data, self.test_data=self.split_train_test(rating_data)\n",
    "        self.csr_train, self.csr_test=self.make_csr(self.train_data,self.test_data)\n",
    "        \n",
    "        self.test_dict={}\n",
    "        for user in range(self.n_user):\n",
    "            self.test_dict[user]=self.csr_test.getrow(user).nonzero()[1]\n",
    "        self.relu=torch.nn.ReLU()    \n",
    "        \n",
    "        self.pair_dist=torch.nn.PairwiseDistance(p=2)\n",
    "        \n",
    "        self.P=torch.nn.Parameter(torch.normal(mean=0,std=1/(self.n_factor**0.5),size=(self.n_user,self.n_factor)))\n",
    "        self.Q=torch.nn.Parameter(torch.normal(mean=0,std=1/(self.n_factor**0.5),size=(self.n_item,self.n_factor)))\n",
    "#         self.P=Variable(torch.normal(mean=0,std=1/(self.n_factor**0.5),size=(self.n_user,self.n_factor)),requires_grad=True)\n",
    "#         self.Q=Variable(torch.normal(mean=0,std=1/(self.n_factor**0.5),size=(self.n_item,self.n_factor)),requires_grad=True)\n",
    "    \n",
    "        self.loss=torch.nn.MSELoss(reduction='sum') \n",
    "\n",
    "#         self.clip_p=tf1.assign(P,tf.clip_by_norm(P,1,axes=[1]))\n",
    "#         self.clip_q = tf1.assign(Q, tf.clip_by_norm(Q, 1, axes=[1]))    \n",
    "        \n",
    "    def run(self):\n",
    "        for epoch in range(self.epoch):\n",
    "            # randomly choose user, movie id\n",
    "            loss=self.train()\n",
    "            start=timer()\n",
    "            if epoch%5==0:\n",
    "                \n",
    "                hit_50,hit_100=self.test()\n",
    "                if epoch%10==0:\n",
    "                    print(\"loss \",loss)\n",
    "                    print(str(epoch)+\". \"+str(timer()-start))\n",
    "                    start=timer()\n",
    "                    print(str(epoch+1)+\". recall@50 : \"+str(hit_50)+\" , recall@100 : \"+str(hit_100))\n",
    "          \n",
    "        \n",
    "    def predict(self,u_neg_item,u_id):\n",
    "        predict_val=self.pair_dist(self.P[u_id,:],self.Q[u_neg_item,:])\n",
    "        return predict_val\n",
    "    \n",
    "    \n",
    "    def recall_at_k(self,k,pred_item,test_item_id):\n",
    "        k=k if len(test_item_id)>k else len(test_item_id)\n",
    "        pred_item_lim=pred_item[:k]\n",
    "        hit_id=np.intersect1d(pred_item_lim,test_item_id)\n",
    "        return len(hit_id)/float(k)\n",
    "    \n",
    "    \n",
    "    def test(self):\n",
    "        ranked_arr={}\n",
    "        hit_50=[]\n",
    "        hit_100=[]\n",
    "        for u in self.test_user:\n",
    "            u_id=[]\n",
    "            # movie id not rated by user,u\n",
    "            u_neg_item=np.array(self.neg_items[u])\n",
    "            u_id=np.repeat(u,len(u_neg_item))\n",
    "            pre_rating=self.predict(u_neg_item,u_id)\n",
    "            neg_item_index=np.array([u_neg_item,pre_rating.detach().numpy()]).T\n",
    "            \n",
    "            # 0 col : item id sorted by pred_rating\n",
    "            # 1 col : predicted rating sorted\n",
    "            ranked_arr[u]=neg_item_index[neg_item_index[:,1].argsort()[::-1]][:,0]\n",
    "            # item id sorted\n",
    "            pred_ratings_50=ranked_arr[u][:50]\n",
    "            pred_ratings_100=ranked_arr[u][:100]\n",
    "            hit_rate_50=self.recall_at_k(50,pred_ratings_50,self.test_dict[u])\n",
    "            hit_rate_100=self.recall_at_k(100,pred_ratings_100,self.test_dict[u])\n",
    "            \n",
    "            if hit_rate_50 !=0:\n",
    "                hit_50.append(hit_rate_50)\n",
    "            if hit_rate_100 !=0:\n",
    "                hit_100.append(hit_rate_100)\n",
    "            \n",
    "        return np.mean(hit_50), np.mean(hit_100)\n",
    "    \n",
    "    def train(self):\n",
    "        train=self.csr_train.tocoo()\n",
    "        row=train.row.reshape(-1)\n",
    "        col=train.col.reshape(-1)\n",
    "        # randomize the order\n",
    "        index=np.random.permutation(self.n_training)\n",
    "        #to list\n",
    "        u_random=torch.tensor(list(row[index])).cuda()\n",
    "        i_random=torch.tensor(list(col[index])).cuda()\n",
    "        item_random_neg=[]\n",
    "        \n",
    "        # randomly choose one item id not rated by each user and put into list\n",
    "        for user in u_random:\n",
    "            n_random=np.random.randint(len(self.neg_items[user.item()]))\n",
    "            item_random_neg.append(self.neg_items[user.item()][n_random])\n",
    "            \n",
    "        item_random_neg=torch.tensor(item_random_neg).cuda()    \n",
    "            \n",
    "        \"\"\"\n",
    "        train : loop for each batch\n",
    "        \"\"\"\n",
    "        loss=0\n",
    "    \n",
    "        for b in range(self.n_batch):\n",
    "            batch_user=u_random[b*self.batch_size:(b+1)*self.batch_size]\n",
    "            batch_item=i_random[b*self.batch_size:(b+1)*self.batch_size]\n",
    "            batch_item_neg=item_random_neg[b*self.batch_size:(b+1)*self.batch_size]\n",
    "            optim=torch.optim.Adagrad([self.P,self.Q],lr=0.1)\n",
    "            optim.zero_grad()\n",
    "            loss=self.loss_m(batch_user,batch_item,batch_item_neg)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            \n",
    "        return loss\n",
    "    \n",
    "    \n",
    "    def loss_m(self,user_id,item_id,neg_item_id):\n",
    "        dist=self.relu(self.margin-self.pair_dist(self.P[user_id.tolist()],self.Q[neg_item_id.tolist()])+self.pair_dist(self.P[user_id.tolist()],self.Q[item_id.tolist()]))\n",
    "        total_loss=torch.sum(dist)\n",
    "        return total_loss\n",
    "    \n",
    "    \n",
    "    def split_train_test(self,rating_data):\n",
    "        \"\"\"\n",
    "        Split to train and test set \n",
    "        \"\"\"\n",
    "        train_data,test_data=train_test_split(rating_data,test_size=self.div_size)\n",
    "        train_data[:,0]-=1\n",
    "        train_data[:,1]-=1\n",
    "        train_data[:,2]=1\n",
    "        test_data[:,0]-=1\n",
    "        test_data[:,1]-=1\n",
    "        test_data[:,2]=1\n",
    "        return train_data,test_data\n",
    "    \n",
    "    \n",
    "    def make_csr(self,train_data,test_data):\n",
    "        \"\"\"\n",
    "        return csr_matrx : train , test\n",
    "        \"\"\"\n",
    "        return csr_matrix((train_data[:,2],(train_data[:,0],train_data[:,1]))), csr_matrix((test_data[:,2],(test_data[:,0],test_data[:,1])))\n",
    "        \n",
    "        \n",
    "    def data_setting(self):\n",
    "        \n",
    "        self.n_training=len(self.train_data[:,0])\n",
    "        self.n_batch=int(self.n_training/self.batch_size)\n",
    "        \n",
    "        #dictionary\n",
    "        self.neg_items=self.neg_item_dic()\n",
    "        self.test_user=set(self.test_data[:,0])\n",
    "        \n",
    "    def neg_item_dic(self):\n",
    "        all_item=set(np.arange(self.n_item))\n",
    "        neg_item={}\n",
    "        for user_id in range(self.n_user):\n",
    "            # 각 user마다 rating하지 않은 item을 list형태로 저장\n",
    "            neg_item[user_id]=list(all_item-set(self.csr_train.getrow(user_id).nonzero()[1]))\n",
    "        return neg_item\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
