{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from dataset import load_data\n",
    "import torch\n",
    "import pickle \n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "import torch.nn.functional as F\n",
    "from timeit import default_timer as timer \n",
    "\n",
    "\n",
    "class GCNLayer(torch.nn.Module):\n",
    "    def __init__(self,input_dim,output_dim,activation=True):\n",
    "        super(GCNLayer,self).__init__()\n",
    "        self.linear=torch.nn.Linear(input_dim,output_dim)\n",
    "        glort_beng=sqrt(6)/sqrt(input_dim+output_dim)\n",
    "        self.linear.weight.data.uniform_(-glort_beng,glort_beng)\n",
    "        self.activation=torch.nn.ReLU() if activation else None\n",
    "            \n",
    "    def forward(self,input_data):\n",
    "        output=self.linear(input_data)\n",
    "        return self.activation(output) if self.activation!=None else output\n",
    "\n",
    "    \n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self,config):\n",
    "        super(GCN,self).__init__()\n",
    "        self.epoch=config['epoch']\n",
    "        self.gcn_l1=GCNLayer(config['input_l1_dim'],config['output_l1_dim'])\n",
    "        self.gcn_l2=GCNLayer(config['output_l1_dim'],config['output_l2_dim'],activation=False)\n",
    "        self.dropout=torch.nn.Dropout(config['dropout'])\n",
    "        self.lr=config['lr']\n",
    "        self.best_accuracy=0.0\n",
    "        self.max_trial=5\n",
    "        self.cur_trial=0\n",
    "        self.loss=torch.nn.CrossEntropyLoss(reduction='none')\n",
    "        \n",
    "    def preprocess_A_hat(self,adj_mtx):\n",
    "        # A_hat\n",
    "        I=np.eye(adj_mtx.shape[0])\n",
    "        A_=adj_mtx+I\n",
    "        D_=np.sum(A_,axis=1)\n",
    "        D_inv_sqrt=np.power(D_,-0.5)\n",
    "        D_inv_sqrt[np.isinf(D_inv_sqrt)]=0.0\n",
    "        D_inv_sqrt=np.diag(D_inv_sqrt)\n",
    "        A_hat=np.dot(np.dot(D_inv_sqrt,A_),D_inv_sqrt)\n",
    "        return torch.from_numpy(A_hat).cuda()\n",
    "        \n",
    "    def forward(self, A_hat, feature):\n",
    "        \"\"\"\n",
    "        parmeter : Preprocessed Adjacency matrix, Feature array (Node(V) X # of Feature)\n",
    "        \"\"\"\n",
    "        arr_layer_1=torch.mm(A_hat,feature)\n",
    "        arr_layer_1=self.gcn_l1(arr_layer_1)\n",
    "        arr_layer_1=self.dropout(arr_layer_1)\n",
    "        arr_layer_2=torch.mm(A_hat,arr_layer_1)\n",
    "        arr_layer_2=self.gcn_l2(arr_layer_2)\n",
    "        return F.log_softmax(arr_layer_2,dim=1)\n",
    "    \n",
    "    def accuracy(self,output,label,msk):\n",
    "        # predict\n",
    "        predict_class=torch.argmax(output[msk],dim=1)\n",
    "        # target\n",
    "        predict_class=predict_class.numpy()\n",
    "        target_class=label[msk].numpy()\n",
    "        ratio_correct= predict_class == target_class\n",
    "        msk=msk.float().numpy()\n",
    "        correct=np.sum(ratio_correct*msk)\n",
    "        return correct/np.sum(msk)\n",
    "    \n",
    " \n",
    "        \n",
    "    @staticmethod    \n",
    "    def run(model,train_msk,valid_msk,test_msk,label,adj):\n",
    "        label_total=label\n",
    "        label=torch.argmax(label,dim=1)\n",
    "        A_hat=model.preprocess_A_hat(adj)\n",
    "        start_total=timer()\n",
    "        \n",
    "        optimizer=torch.optim.Adam(model.parameters(),lr=model.lr)\n",
    "        for e in range(model.epoch):\n",
    "            start=timer()\n",
    "            model.train()\n",
    "            output=model(A_hat,feature_cat)\n",
    "            train_loss=F.nll_loss(output[train_msk],label_total[train_msk])\n",
    "#             train_loss=model.loss(output[train_msk],label[train_msk])\n",
    "            model.eval()\n",
    "            valid_accuracy=model.accuracy(output,label,valid_msk)\n",
    "            if not model.early_stop(valid_accuracy):\n",
    "                print(\"Last Epoch : {:d}, accuracy : {:.4f}\".format(e+1,valid_accuracy))\n",
    "                break\n",
    "            if e%20 ==0:\n",
    "                print(\"Epoch : {:d}, Train Loss : {:.4f}, Accuracy : {:.4f}, Time : {:.4f}\".format(e+1,train_loss.item(),valid_accuracy,timer()-start))\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        model.eval()\n",
    "        output=model(A_hat,feature_cat)\n",
    "        test_accuracy=F.nll_loss(output[test_msk],label[test_msk])\n",
    "        print(\"Accuracy : {:.4f}, Time : {:.4f}\".format(test_accuracy,timer()-start_total))\n",
    "        \n",
    "            \n",
    "            \n",
    "    def early_stop(self,accur):\n",
    "        if self.best_accuracy<accur:\n",
    "            self.cur_trial=0\n",
    "            self.best_accuracy=accur\n",
    "            return True\n",
    "        elif self.max_trial>self.cur_trial:\n",
    "            self.cur_trial+=1\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj, feature_cat,train_label,test_label,valid_label, train_msk, test_msk, valid_msk, label=load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\n",
    "    'epoch':200,\n",
    "    'input_l1_dim':feature_cat.shape[1],\n",
    "    'output_l1_dim':16,\n",
    "    'output_l2_dim':train_label.shape[1],\n",
    "    'dropout':0.5,\n",
    "    'lr':0.01\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0540, -0.0006,  0.0372,  ..., -0.0230, -0.0614,  0.0397],\n",
      "        [ 0.0213, -0.0465,  0.0503,  ..., -0.0414, -0.0310, -0.0014],\n",
      "        [ 0.0155,  0.0398,  0.0573,  ..., -0.0388,  0.0526,  0.0445],\n",
      "        ...,\n",
      "        [ 0.0330, -0.0041,  0.0099,  ...,  0.0307,  0.0083,  0.0539],\n",
      "        [ 0.0034, -0.0407, -0.0116,  ..., -0.0322,  0.0509,  0.0272],\n",
      "        [ 0.0280, -0.0567,  0.0039,  ..., -0.0431,  0.0466,  0.0627]])\n",
      "tensor([[-2.4051e-01,  1.5408e-01,  1.1047e-01, -8.0049e-02,  4.4256e-01,\n",
      "         -3.5917e-02, -3.8854e-01,  2.6265e-01,  4.3224e-01, -3.9024e-02,\n",
      "          2.4527e-01, -6.1114e-02, -3.5806e-01,  3.0861e-01,  1.5660e-01,\n",
      "         -1.8800e-01],\n",
      "        [ 1.3941e-01,  4.0672e-01, -4.7329e-01,  4.5901e-02,  3.1536e-01,\n",
      "          4.5159e-01, -4.1599e-01, -7.9307e-02,  8.2355e-02, -3.0291e-01,\n",
      "          4.6027e-01,  1.1787e-01, -2.1371e-01, -3.5970e-01, -3.5590e-01,\n",
      "          2.4978e-01],\n",
      "        [-3.5973e-01,  4.4280e-01,  1.2441e-01,  3.6487e-01, -3.7703e-01,\n",
      "          1.7184e-01, -3.7407e-01, -4.8767e-01, -4.3267e-01,  1.1928e-01,\n",
      "         -5.0317e-01,  2.2951e-01,  3.6219e-01, -4.7300e-01,  4.3332e-01,\n",
      "          4.4754e-01],\n",
      "        [ 1.4241e-01, -1.6305e-01,  4.3640e-01, -6.3038e-02, -4.0335e-02,\n",
      "         -4.4830e-01,  4.9317e-01, -2.8434e-01,  3.9578e-01, -3.4190e-01,\n",
      "         -2.1208e-01, -4.5986e-01, -4.1365e-01, -1.2353e-01,  3.2743e-01,\n",
      "         -4.7445e-01],\n",
      "        [-2.6330e-01,  1.0217e-01,  2.0618e-01, -5.0153e-02, -2.6794e-01,\n",
      "         -1.5908e-01,  4.2257e-01, -4.3191e-01, -3.9597e-01, -6.2755e-02,\n",
      "         -2.8473e-01,  2.1632e-01, -1.8452e-01,  2.8894e-01, -4.5506e-01,\n",
      "         -4.4779e-01],\n",
      "        [-4.0173e-04,  4.0423e-01, -4.7620e-01, -1.5895e-01, -3.4724e-01,\n",
      "          1.6237e-01, -2.4451e-01,  5.4977e-02, -4.4705e-01,  1.9426e-01,\n",
      "          3.4052e-01,  2.4413e-01,  4.4647e-01,  6.0140e-02, -4.0899e-01,\n",
      "          3.4307e-01],\n",
      "        [ 3.4234e-01, -3.6863e-01, -3.3950e-01,  3.9416e-01,  3.3718e-01,\n",
      "         -3.1654e-02,  4.0891e-01, -4.5209e-01, -3.4196e-01,  4.4781e-01,\n",
      "          3.5637e-01, -2.5829e-01, -3.7576e-01,  1.3334e-02,  2.7969e-01,\n",
      "         -4.8639e-01]])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Float but found Double",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-21f308ca6c48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mgcn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mGCN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mGCN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgcn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_msk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_msk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_msk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0madj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-42fccf191be1>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(model, train_msk, valid_msk, test_msk, label, adj)\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA_hat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeature_cat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m             \u001b[0mtrain_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_msk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel_total\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_msk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;31m#             train_loss=model.loss(output[train_msk],label[train_msk])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kibum/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-42fccf191be1>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, A_hat, feature)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \"\"\"\n\u001b[1;32m     54\u001b[0m         \u001b[0marr_layer_1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA_hat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0marr_layer_1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgcn_l1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_layer_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0marr_layer_1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_layer_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0marr_layer_2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA_hat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0marr_layer_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kibum/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-42fccf191be1>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_data)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kibum/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kibum/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kibum/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1688\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1689\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1690\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1691\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1692\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected scalar type Float but found Double"
     ]
    }
   ],
   "source": [
    "gcn=GCN(config).cuda()\n",
    "GCN.run(gcn,train_msk,valid_msk,test_msk,label,adj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects=[]\n",
    "suffix=['x','y','allx','ally','tx','ty','graph']\n",
    "for s in suffix:\n",
    "    objects.append(pickle.load(open('./data/ind.cora.'+s,'rb'),encoding='latin1'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=torch.tensor([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.array([True,True,False,False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=np.array([False,True,False,True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=torch.from_numpy(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.float().numpy()*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_index=[]\n",
    "with open('./data/ind.cora.test.index','rb') as file:\n",
    "    line=file.readline()\n",
    "    while len(line)>0:\n",
    "        test_index.append(int(line[0:-1]))\n",
    "        line=file.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.diag(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
