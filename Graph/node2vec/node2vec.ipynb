{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from dataset import load_graph\n",
    "import random\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "\n",
    "class node2vec(object):\n",
    "    def __init__(self,config):\n",
    "        self.graph=load_graph(config['graph_path'],weight=False).to_undirected()\n",
    "        self.r=config['r']\n",
    "        self.walk_length=config['walk_length']\n",
    "        self.dim=config['dim']\n",
    "        self.p=config['p']\n",
    "        self.q=config['q']\n",
    "        self.window=config['window']\n",
    "        \n",
    "        \n",
    "    def walking(self):\n",
    "        walks=[]\n",
    "        nodes=list(self.graph.nodes)\n",
    "        for i in range(self.r):\n",
    "            random.shuffle(nodes)\n",
    "            for n in nodes:\n",
    "                walks.append(self.node2vec_walk(n))\n",
    "        return walks\n",
    "                \n",
    "    def node2vec_walk(self,src):\n",
    "        walk=[src]\n",
    "        while len(walk) < self.walk_length:\n",
    "            cur_node=walk[-1]\n",
    "            cur_node_neigh=sorted(self.graph.neighbors(cur_node))\n",
    "            if len(cur_node_neigh)>0:\n",
    "                # For walking at first\n",
    "                if len(walk)==1:\n",
    "                    walk.append(cur_node_neigh[self.direct_to_node(self.alias_nodes[cur_node][0],self.alias_nodes[cur_node][1])])\n",
    "                else:\n",
    "                    pre_node=walk[-2]\n",
    "                    next_node=cur_node_neigh[self.direct_to_node(self.alias_edges[(pre_node,cur_node)][0],self.alias_edges[(pre_node,cur_node)][1])]\n",
    "                    walk.append(next_node)\n",
    "            else:\n",
    "                break\n",
    "        return walk    \n",
    "    \n",
    "    def preprocess_Modified(self):\n",
    "        # Weight Setting\n",
    "        for edge in self.graph.edges():\n",
    "            self.graph[edge[0]][edge[1]]['weight']=1\n",
    "            self.graph[edge[1]][edge[0]]['weight']=1\n",
    "            \n",
    "        alias_nodes={}\n",
    "        alias_edges={}\n",
    "        \n",
    "        # For alias sampling\n",
    "        # alias nodes would be used when walking starts at first\n",
    "        for node in self.graph.nodes():\n",
    "            node_prob=[self.graph[node][n]['weight'] for n in sorted(self.graph.neighbors(node))]\n",
    "            Z=float(sum(node_prob))\n",
    "            normalize_prob=[e/Z for e in node_prob]\n",
    "            alias_nodes[node]=self.alias_setting(normalize_prob)\n",
    "            \n",
    "        # For alias sampling \n",
    "        # alias edge would be used after the walking at first\n",
    "        # Undirected Graph\n",
    "        for edge in self.graph.edges():\n",
    "            alias_edges[edge]=self.get_alias_edge(edge[0],edge[1])\n",
    "            alias_edges[(edge[1],edge[0])]=self.get_alias_edge(edge[1],edge[0])\n",
    "            \n",
    "        self.alias_nodes=alias_nodes\n",
    "        self.alias_edges=alias_edges\n",
    "    \n",
    "    \n",
    "    def get_alias_edge(self,src,dst):\n",
    "        \"\"\"\n",
    "        For preprocess the transition probability\n",
    "        \"\"\"\n",
    "        edge_prob=[]\n",
    "        for dst_neighbor in sorted(self.graph.neighbors(dst)):\n",
    "            # distance : 0\n",
    "            if dst_neighbor==src:\n",
    "                edge_prob.append(self.graph[dst][dst_neighbor]['weight']/self.p)\n",
    "            # distance : 1\n",
    "            elif self.graph.has_edge(dst_neighbor,src):\n",
    "                edge_prob.append(self.graph[dst][dst_neighbor]['weight'])\n",
    "            # distance : 2\n",
    "            else:\n",
    "                edge_prob.append(self.graph[dst][dst_neighbor]['weight']/self.q)\n",
    "        Z=float(sum(edge_prob))\n",
    "        norm_prob=[e/Z for e in edge_prob]\n",
    "        return self.alias_setting(norm_prob)    \n",
    "    \n",
    "    def alias_setting(self,prob):\n",
    "        \"\"\"\n",
    "        Alias Method\n",
    "        reference : https://en.wikipedia.org/wiki/Alias_method (table generation)\n",
    "        At Last, U_i is filled with value of smaller than 1\n",
    "        \"\"\"\n",
    "        n=len(prob)\n",
    "        U=np.zeros(n)\n",
    "        # for floor the value\n",
    "        K=np.zeros(n, dtype=np.int)\n",
    "        overfull=[]\n",
    "        underfull=[]\n",
    "        for i,p in enumerate(prob):\n",
    "            U[i]=n*p\n",
    "            if U[i]<1.0:\n",
    "                underfull.append(i)\n",
    "            else:\n",
    "                overfull.append(i)\n",
    "                \n",
    "        while len(overfull)>0 and len(underfull)>0:\n",
    "            under=underfull.pop()\n",
    "            over=overfull.pop()\n",
    "            K[under]=over\n",
    "            U[over]+=U[under]-1.0\n",
    "            if U[over]<1.0:\n",
    "                underfull.append(over)\n",
    "            else:\n",
    "                overfull.append(over)\n",
    "        return K,U\n",
    "            \n",
    "        \n",
    "    def direct_to_node(self,K,U):\n",
    "        \"\"\"\n",
    "        Direct to next node using alias sampling \n",
    "        \"\"\"\n",
    "        n=len(K)\n",
    "        node=int(np.floor(np.random.rand()*n))\n",
    "        return node if np.random.rand()<U[node] else K[node]\n",
    "    def make_string(self,walks):\n",
    "        walk=[]\n",
    "        for i in walks:\n",
    "            temp=[]\n",
    "            for j in i:\n",
    "                temp.append(str(j))\n",
    "            walk.append(temp)\n",
    "        return walk\n",
    "    \n",
    "    @staticmethod\n",
    "    def run(graph):\n",
    "        start=timer()\n",
    "        print(\"Preprocess Start\")\n",
    "        graph.preprocess_Modified()\n",
    "        print(\"Preprocess Finish, Time :{:.4f}\".format(timer()-start))\n",
    "        start=timer()\n",
    "        walks=graph.walking()\n",
    "        print(\"Walking Finish, Time : {:.4f}\".format(timer()-start))\n",
    "#         flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "#         walks=[map(str,i) for i in walks]\n",
    "        walks=graph.make_string(walks)\n",
    "        start=timer()\n",
    "        model=Word2Vec(sentences=walks, size=graph.dim,window=graph.window,min_count=0,sg=1,workers=8,iter=1)\n",
    "        print(\"SGD Finish, Time : {:.4f}\".format(timer()-start))\n",
    "        return model.wv\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import load_data,load_graph\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "class Prediction(object):\n",
    "    def __init__(self,feature_vector):\n",
    "        self.vector=feature_vector\n",
    "        self.adj, _,_,_,_,_,_,_,label=load_data()\n",
    "        self.label=label.cpu()\n",
    "        self.graph=load_graph().to_undirected()\n",
    "        \n",
    "    def link_prediction_classifier(self,max_iter=2000):\n",
    "        lr_clf = LogisticRegressionCV(Cs=10, cv=10, scoring=\"roc_auc\", max_iter=max_iter)\n",
    "        return Pipeline(steps=[(\"sc\", StandardScaler()), (\"clf\", lr_clf)])    \n",
    "    \n",
    "    def evaluate_link_prediction(self):\n",
    "        \n",
    "    \n",
    "    def load_label(path='../data/ind.cora.y'):\n",
    "        label=None\n",
    "        with open(path,'rb') as file:\n",
    "            label=pickle.load(file)\n",
    "        return label\n",
    "    \n",
    "    \n",
    "    def train_link_prediction_model(self):\n",
    "        clf=self.link_prediction_classifier()\n",
    "        link_feature,label=self.link_example_to_feature()\n",
    "        clf.fit(link_feature,label)\n",
    "        return clf\n",
    "        \n",
    "    def link_example_to_feature(self):\n",
    "        link_feature=[]\n",
    "        label=[]\n",
    "        node=sorted(list(self.graph.nodes()))\n",
    "        for index,node_1 in enumerate(node):\n",
    "            for node_2 in node[index,:]:\n",
    "                if node_1 == node_2:\n",
    "                    continue\n",
    "                if self.graph.has_edge(node_1,node_2):\n",
    "                    label.append(1)\n",
    "                    link_feature.append(self.binary_operator(node_1,node_2))\n",
    "                else:\n",
    "                    label.append(0)\n",
    "                    link_feature.append(self.binary_operator(node_1,node_2))\n",
    "        train_link\n",
    "        return link_feature,label\n",
    "                \n",
    "    \n",
    "    def binary_operator(self,src,dst):\n",
    "        return np.asarray(self.vector[str(src)])*np.asarray(self.vector[str(dst)])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "config={'r':10,\n",
    "        'walk_length':80,\n",
    "        'dim':128,\n",
    "        'p':1,\n",
    "        'q':1,\n",
    "        'graph_path':'../data/ind.cora',\n",
    "        'window':10\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph=node2vec(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocess Start\n",
      "Preprocess Finish, Time :0.3184\n",
      "Walking Finish, Time : 8.6896\n",
      "SGD Start\n",
      "SGD Finish, Time : 5.8401\n"
     ]
    }
   ],
   "source": [
    "vector=node2vec.run(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.83663785e-02,  1.07074723e-01, -1.45433471e-01,  7.72097111e-02,\n",
       "       -1.74917608e-01,  1.48178667e-01, -4.80675519e-01,  9.81525630e-02,\n",
       "       -2.07178250e-01,  5.25613278e-02,  5.82001843e-02, -3.94587934e-01,\n",
       "        2.39404395e-01, -2.18963306e-02,  3.25878225e-02, -1.46705374e-01,\n",
       "        5.22884846e-01, -2.51476496e-01,  5.97268939e-01, -4.78149831e-01,\n",
       "        5.11971302e-03, -1.02224583e-02,  4.55449313e-01, -2.87113577e-01,\n",
       "       -3.33695225e-02, -7.52046183e-02, -1.08576603e-02, -1.98904037e-01,\n",
       "       -1.93848670e-01,  1.85810596e-01,  7.40599692e-01, -6.85704648e-01,\n",
       "       -2.58348197e-01,  2.74352878e-01,  2.69702345e-01,  2.45061591e-01,\n",
       "       -2.61042178e-01, -3.05080295e-01, -5.61426058e-02,  6.17093071e-02,\n",
       "       -4.75103438e-01, -3.52188528e-01,  1.94744438e-01,  4.83613938e-01,\n",
       "        7.53225153e-03, -5.62273026e-01,  1.16552167e-01,  6.32723093e-01,\n",
       "       -4.51847725e-02, -1.13065034e-01,  1.85359836e-01, -3.47874761e-01,\n",
       "       -5.90517104e-01, -5.34780741e-01,  1.91694319e-01,  2.58192629e-01,\n",
       "        1.80132329e-01, -3.74535173e-01, -2.87544638e-01, -3.32420617e-01,\n",
       "       -2.37727165e-01,  3.88966590e-01, -1.54196411e-01,  4.08554286e-01,\n",
       "       -3.92648578e-02,  7.57742822e-02, -3.06297660e-01, -3.28191556e-02,\n",
       "       -7.11649120e-01,  2.95074135e-01, -2.95149893e-01,  1.24043645e-02,\n",
       "        3.09072137e-01,  5.70512451e-02,  3.28637194e-03,  2.69472337e-04,\n",
       "        6.17940605e-01, -6.18845880e-01,  4.87891473e-02,  2.71508008e-01,\n",
       "        3.51723522e-01,  3.27741385e-01,  6.47726536e-01, -8.50389600e-02,\n",
       "        2.18143329e-01, -4.98281866e-02, -7.67278224e-02,  5.03475824e-03,\n",
       "        2.17541549e-02, -2.28716940e-01, -7.70361304e-01, -4.27737325e-01,\n",
       "        5.98654985e-01, -5.41245341e-01,  2.17898507e-02, -4.24720138e-01,\n",
       "       -1.67508915e-01,  1.49147645e-01, -5.79923868e-01, -1.36225253e-01,\n",
       "       -6.06019020e-01, -3.90129276e-02, -2.27678001e-01, -2.22383156e-01,\n",
       "       -3.04962993e-01, -4.62235063e-01,  7.05195904e-01,  6.99859560e-01,\n",
       "        9.88155827e-02,  2.13885009e-01, -4.37147051e-01, -4.33107287e-01,\n",
       "        1.91554666e-01,  3.29873204e-01,  1.88952848e-01,  4.47808998e-03,\n",
       "       -4.44026828e-01, -6.59970939e-01,  1.30822440e-03,  4.74258095e-01,\n",
       "       -5.37086697e-03, -7.91938230e-02, -6.41359016e-02, -5.34591436e-01,\n",
       "        4.63758260e-01, -1.87784448e-01,  2.11125180e-01, -2.85369698e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector['0']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}